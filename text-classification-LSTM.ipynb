{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ILMNX/Pattern-recognition/blob/main/text-classification-LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences # Menyelaraskan panjang input data teks dengan padding, agar semua input\n",
        "# memiliki panjang yang seragam.\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential # Digunakan untuk membuat model urutan yang terdiri dari layer berturut-turut.\n",
        "\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dropout, Dense, Bidirectional\n",
        " # embeding : Layer pertama dalam model untuk memetakan kata ke dalam representasi vektor berdimensi rendah.\n",
        " # LSTM : Merupakan tipe RNN (Recurrent Neural Network) yang digunakan untuk memproses data urutan, misalnya teks.\n",
        " # Dropout : Digunakan untuk regularisasi model dengan membuang (drop) neuron secara acak selama pelatihan, untuk mencegah overfitting.\n",
        " # Dense :  Layer yang sepenuhnya terhubung (fully connected layer), biasanya digunakan untuk output akhir dari model.\n",
        " # Bidirectional : Membungkus LSTM atau GRU untuk memproses data dalam dua arah (forward dan backward).\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "# EarlyStooping : Digunakan untuk menghentikan pelatihan model secara otomatis jika akurasi model tidak\n",
        "# meningkat setelah sejumlah epoch tertentu, untuk mencegah overfitting.\n"
      ],
      "metadata": {
        "id": "_2voOTjLAfZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [\"I love programming\", \"I hate bugs\", \"Deep learning is amazing\", \"I dislike errors\",\n",
        "         \"This is a great product\", \"Terrible service\", \"The food was delicious\", \"The movie was boring\",\n",
        "         \"I am very happy\", \"I am very sad\"] * 100 # Perbanyak data\n",
        "labels = [1, 0, 1, 0, 1, 0, 1, 0, 1, 0] * 100"
      ],
      "metadata": {
        "id": "_geBrtaf-SRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Penjelasan :     \n",
        "\n",
        "* texts menjadi list berisi 1000 kalimat yang mencerminkan opini atau perasaan.\n",
        "labels menjadi list berisi 1000 label yang menunjukkan apakah kalimat tersebut bersifat positif (1) atau negatif (0).\n",
        "* Tujuan\n",
        "texts dan labels ini biasanya digunakan dalam pelatihan model klasifikasi teks, di mana model akan mempelajari pola dalam kalimat (dari texts) dan memprediksi labelnya (positif atau negatif) berdasarkan data latih tersebut."
      ],
      "metadata": {
        "id": "-wY5GFwoEMtn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenisasi dan padding\n",
        "max_words = 10000\n",
        "max_sequence_length = 100\n",
        "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "X = pad_sequences(sequences, maxlen=max_sequence_length)\n",
        "y = np.array(labels)\n"
      ],
      "metadata": {
        "id": "op58QSkr-TFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Penjelasan :   \n",
        "Kode ini melakukan tokenisasi dan padding pada data teks. Pertama, **`Tokenizer`** digunakan untuk mengonversi teks menjadi urutan angka dengan membatasi jumlah kata hingga **10.000** dan menyertakan token untuk kata yang tidak dikenal (**`oov_token=\"<OOV>\"`**). Kemudian, **`fit_on_texts(texts)`** melatih tokenizer berdasarkan data teks, dan **`texts_to_sequences(texts)`** mengonversi teks menjadi urutan angka. Setelah itu, **`pad_sequences`** digunakan untuk menyamakan panjang setiap urutan teks hingga **100 kata**. Data teks yang sudah diproses disimpan di **`X`**, sementara labelnya disimpan di **`y`** sebagai array NumPy."
      ],
      "metadata": {
        "id": "SU71mkDxEc8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bagi dataset menjadi data pelatihan dan pengujian\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n"
      ],
      "metadata": {
        "id": "kS_ee_fa-X6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Langkah 2: Membangun Model LSTM\n",
        "\n",
        "embedding_dim = 128  # Dimensi embedding\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_words, embedding_dim, input_length=max_sequence_length))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True))) # Bidirectional LSTM\n",
        "model.add(Dropout(0.2)) # Tambah dropout\n",
        "model.add(Bidirectional(LSTM(32))) # Bidirectional LSTM\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dropout(0.2)) # Tambah dropout\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "7EBLQ5Uq-a5s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c7e1873-5264-4ffa-8832-15be6486e91c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Penjelasan :      \n",
        "\n",
        "  Kode ini membangun model **LSTM** untuk klasifikasi teks. Pertama, **`Embedding`** digunakan untuk mengonversi kata menjadi vektor berdimensi **128**. Kemudian, dua **Bidirectional LSTM** ditambahkan, yang memungkinkan model memproses data dari kedua arah (maju dan mundur), dengan unit LSTM pertama berukuran 64 dan yang kedua berukuran 32. **`Dropout`** dengan rate 0.2 digunakan untuk mencegah overfitting. Setelah itu, layer **`Dense`** dengan 16 neuron dan fungsi aktivasi **ReLU** ditambahkan untuk pemrosesan lebih lanjut, diikuti dengan **`Dropout`** lagi. Terakhir, layer **`Dense`** dengan 1 neuron dan aktivasi **sigmoid** digunakan untuk menghasilkan output biner (0 atau 1), yang cocok untuk klasifikasi dua kelas."
      ],
      "metadata": {
        "id": "p5NWaWR9Exak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Langkah 3: Kompilasi dan Pelatihan Model\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True) # Early stopping\n",
        "model.fit(X_train, y_train, epochs=20, batch_size=64, validation_split=0.1, callbacks=[early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Be6YMf7-eET",
        "outputId": "afb312d5-2d18-4427-e530-541101e40d9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 379ms/step - accuracy: 0.5216 - loss: 0.6856 - val_accuracy: 0.6625 - val_loss: 0.6227\n",
            "Epoch 2/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 463ms/step - accuracy: 0.7502 - loss: 0.5530 - val_accuracy: 1.0000 - val_loss: 0.2280\n",
            "Epoch 3/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 293ms/step - accuracy: 0.9835 - loss: 0.1949 - val_accuracy: 1.0000 - val_loss: 0.0645\n",
            "Epoch 4/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 379ms/step - accuracy: 1.0000 - loss: 0.1011 - val_accuracy: 1.0000 - val_loss: 0.0264\n",
            "Epoch 5/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 295ms/step - accuracy: 1.0000 - loss: 0.0706 - val_accuracy: 1.0000 - val_loss: 0.0118\n",
            "Epoch 6/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 354ms/step - accuracy: 1.0000 - loss: 0.0493 - val_accuracy: 1.0000 - val_loss: 0.0054\n",
            "Epoch 7/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 288ms/step - accuracy: 1.0000 - loss: 0.0343 - val_accuracy: 1.0000 - val_loss: 0.0027\n",
            "Epoch 8/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 291ms/step - accuracy: 1.0000 - loss: 0.0211 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
            "Epoch 9/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 430ms/step - accuracy: 1.0000 - loss: 0.0165 - val_accuracy: 1.0000 - val_loss: 9.5005e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 298ms/step - accuracy: 1.0000 - loss: 0.0090 - val_accuracy: 1.0000 - val_loss: 6.3657e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 296ms/step - accuracy: 1.0000 - loss: 0.0132 - val_accuracy: 1.0000 - val_loss: 4.6627e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 381ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 1.0000 - val_loss: 3.5834e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 352ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 1.0000 - val_loss: 2.8371e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 342ms/step - accuracy: 1.0000 - loss: 0.0074 - val_accuracy: 1.0000 - val_loss: 2.2223e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 318ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 1.0000 - val_loss: 1.8084e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 359ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 1.0000 - val_loss: 1.4374e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 556ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 1.0000 - val_loss: 1.1904e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 292ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 1.0000 - val_loss: 9.8329e-05\n",
            "Epoch 19/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 464ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 1.0000 - val_loss: 8.4294e-05\n",
            "Epoch 20/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 299ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 7.2742e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f9bf5d7d7e0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Penjelasan :     \n",
        "\n",
        "Kode ini mengompilasi dan melatih model LSTM. **`model.compile`** mengonfigurasi model dengan fungsi **loss** `binary_crossentropy` (untuk klasifikasi biner), **optimizer** `adam`, dan metrik **`accuracy`** untuk evaluasi. **`EarlyStopping`** digunakan untuk menghentikan pelatihan jika **loss validasi** tidak membaik setelah 3 epoch, sambil memulihkan bobot model terbaik (dengan `restore_best_weights=True`). Kemudian, **`model.fit`** melatih model menggunakan data latih **`X_train`** dan **`y_train`**, dengan 20 epoch, ukuran batch 64, dan 10% data digunakan untuk validasi (**`validation_split=0.1`**)."
      ],
      "metadata": {
        "id": "OZ1ykD7eFDM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Langkah 4: Evaluasi Model\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Loss: {loss:.4f}\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YevaiIzj-fnB",
        "outputId": "48d8f979-c8f1-49a6-851a-a7327453b0f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 6.8832e-05\n",
            "Loss: 0.0001\n",
            "Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Penjelasan :     \n",
        "\n",
        " Kode ini mengevaluasi performa model pada data uji **`X_test`** dan **`y_test`** menggunakan **`model.evaluate`**. Hasil evaluasi, yaitu **loss** dan **accuracy**, disimpan dalam variabel **`loss`** dan **`accuracy`**, kemudian dicetak dengan format desimal 4 angka setelah koma."
      ],
      "metadata": {
        "id": "KYtvhJALFMSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "vu7-se4K-mfs",
        "outputId": "a074bc76-5cdb-4761-9dec-8aeec57acd43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m1,280,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │          \u001b[38;5;34m98,816\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m41,216\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │           \u001b[38;5;34m1,040\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m17\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">41,216</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,040</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,263,269\u001b[0m (16.26 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,263,269</span> (16.26 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,421,089\u001b[0m (5.42 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,421,089</span> (5.42 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2,842,180\u001b[0m (10.84 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,842,180</span> (10.84 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Penjelasan :     \n",
        "\n",
        "\n",
        "Hasil di atas menunjukkan arsitektur model LSTM yang digunakan. Berikut adalah penjelasannya:\n",
        "\n",
        "1. **`Embedding` Layer**: Mengubah kata-kata menjadi vektor berdimensi 128. Memiliki 1.280.000 parameter (berdasarkan ukuran vocabulary dan embedding dimension).\n",
        "2. **`Bidirectional LSTM` Layer**: Memproses data teks dari dua arah (maju dan mundur) dengan output berukuran 128 dan 98.816 parameter.\n",
        "3. **`Dropout` Layer**: Mencegah overfitting dengan mengatur sebagian neuron menjadi 0 selama pelatihan, tanpa menambah parameter.\n",
        "4. **`Bidirectional LSTM` Layer**: Layer LSTM kedua dengan output 64 dan 41.216 parameter.\n",
        "5. **`Dense` Layer**: Layer dengan 16 neuron dan 1.040 parameter.\n",
        "6. **`Dropout` Layer**: Lagi, mencegah overfitting tanpa menambah parameter.\n",
        "7. **`Dense` Layer**: Output layer dengan 1 neuron untuk klasifikasi biner, dengan 17 parameter.\n",
        "\n",
        "Total parameter model: **4.263.269**, dengan **1.421.089** parameter yang dapat dilatih. Model ini membutuhkan sekitar 16.26 MB memori untuk disimpan."
      ],
      "metadata": {
        "id": "CqmaGTnvFbwU"
      }
    }
  ]
}